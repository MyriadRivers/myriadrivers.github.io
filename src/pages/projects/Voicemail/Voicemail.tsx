import { Project, ProjectTag, Section } from "../../../types";

import Image from "../../../components/Image";
import Video from "../../../components/Video";

import maxImage from "./max_patch.png";
import arduinoImage from "./arduino.png";
import VoicemailCanvas from "../../../components/VoicemailCanvas";
import SoundCloudSmall from "../../../components/SoundCloudSmall";

const title: string = "Voicemail";
const dateRange: string = "Mar 2022";
const links: Array<{ text: string, url: string }> = [
    { text: "front-end GitHub", url: "https://github.com/MyriadRivers/aivf" }
];
const tags: Array<ProjectTag> = [
    ProjectTag.engineering
];
const sections: Array<Section> = [
    {
        shortTitle: "Description",
        title: "Description",
        contents:
            <>
                <SoundCloudSmall
                    artist={"Jason Gao"}
                    track={"Voicemail"}
                    artistURL={"https://soundcloud.com/myriadrivers-558554438"}
                    trackURL={"https://soundcloud.com/myriadrivers-558554438/voicemail?si=819715ce8d3d46ffa1ac10c1e0c78f4d&utm_source=clipboard&utm_medium=text&utm_campaign=social_sharing"}
                    trackID={"1694478468"}
                />
                <p>
                    A composition featuring various cellphone sounds, performed using a controller built with an Arduino.
                </p>
            </>
    },
    {
        shortTitle: "Design",
        title: "Design",
        summary: "The composition was performed using Ableton Live and an Arduino controller",
        contents:
            <>
                <p>
                    A custom controller was built using an Arduino, an ultrasonic sensor, and a slide potentiometer.
                    Gliding a finger along the potentiometer and altering the distance of an object to the ultrasonic sensor would trigger different
                    samples in different groupings using Ableton's Session View.
                </p>
                <Image src={arduinoImage} caption={`The controller made from an Arduino.`} />
                <p>
                    The signals from the Arduino were then routed through a custom Max for Live patch to control which Ableton events to trigger,
                    allowing for a live performance of the composition.
                </p>
                <Image src={maxImage} caption={`The Max MSP patch that controls Ableton.`} />
                <p>
                    The samples of the composition are all sounds generated by a cellphone, with effects and processing applied in Ableton.
                </p>
            </>
    },
    {
        shortTitle: "Art",
        title: "Art",
        summary: "The art for the track was generated randomly on an HTML Canvas with TypeScript",
        contents:
            <>
                <p>
                    The track art consists of a bunch of randomly generated phone numbers. You can make your own below!
                </p>
                <VoicemailCanvas />
            </>
    }
]

const Voicemail: Project = {
    title: title,
    dateRange: dateRange,
    links: links,
    tags: tags,
    sections: sections
}

export default Voicemail;

